<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0"
     xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
     xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/doc/Grobid/Development/grobid/grobid-home/schemas/xsd/Grobid.xsd"
     xmlns:xlink="http://www.w3.org/1999/xlink">
    <teiHeader xml:lang="en">
        <encodingDesc>
            <appInfo>
                <application version="0.5.5-SNAPSHOT" ident="GROBID" when="2019-04-27T14:07+0000">
                    <ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting
                        information from scholarly documents
                    </ref>
                </application>
            </appInfo>
        </encodingDesc>
        <fileDesc>
            <titleStmt>
                <title level="a" type="main">Speech-Activated Text Retrieval System for Cellular Phones with Web
                    Browsing Capability
                </title>
            </titleStmt>
            <publicationStmt>
                <publisher/>
                <availability status="unknown">
                    <licence/>
                </availability>
            </publicationStmt>
            <sourceDesc>
                <biblStruct>
                    <analytic>
                        <author>
                            <persName xmlns="http://www.tei-c.org/ns/1.0">
                                <forename type="first">Takahiro</forename>
                                <surname>Ikeda</surname>
                            </persName>
                            <email>t-ikeda@di.jp.nec.coms-ishikawa@dg.jp.ne.com</email>
                            <affiliation key="aff0">
                                <orgName type="department">Media and Information Research Laboratories</orgName>
                                <orgName type="institution">NEC Corporation</orgName>
                                <address>
                                    <addrLine>Nakahara-Ku</addrLine>
                                    <postCode>1753, 211-8666</postCode>
                                    <settlement>Shimonumabe, Kawasaki</settlement>
                                    <region>Kanagawa</region>
                                    <country key="JP">Japan</country>
                                </address>
                            </affiliation>
                        </author>
                        <author>
                            <persName xmlns="http://www.tei-c.org/ns/1.0">
                                <forename type="first">Shin-Ya</forename>
                                <surname>Ishikawa</surname>
                            </persName>
                            <affiliation key="aff0">
                                <orgName type="department">Media and Information Research Laboratories</orgName>
                                <orgName type="institution">NEC Corporation</orgName>
                                <address>
                                    <addrLine>Nakahara-Ku</addrLine>
                                    <postCode>1753, 211-8666</postCode>
                                    <settlement>Shimonumabe, Kawasaki</settlement>
                                    <region>Kanagawa</region>
                                    <country key="JP">Japan</country>
                                </address>
                            </affiliation>
                        </author>
                        <author>
                            <persName xmlns="http://www.tei-c.org/ns/1.0">
                                <forename type="first">Kiyokazu</forename>
                                <surname>Miki</surname>
                            </persName>
                            <email>k-miki@bq.jp.nec.com</email>
                            <affiliation key="aff0">
                                <orgName type="department">Media and Information Research Laboratories</orgName>
                                <orgName type="institution">NEC Corporation</orgName>
                                <address>
                                    <addrLine>Nakahara-Ku</addrLine>
                                    <postCode>1753, 211-8666</postCode>
                                    <settlement>Shimonumabe, Kawasaki</settlement>
                                    <region>Kanagawa</region>
                                    <country key="JP">Japan</country>
                                </address>
                            </affiliation>
                        </author>
                        <author>
                            <persName xmlns="http://www.tei-c.org/ns/1.0">
                                <forename type="first">Fumihiro</forename>
                                <surname>Adachi</surname>
                            </persName>
                            <email>f-adachi@aj.jp.nec.comr-isotani@bp.jp.nec.com</email>
                            <affiliation key="aff0">
                                <orgName type="department">Media and Information Research Laboratories</orgName>
                                <orgName type="institution">NEC Corporation</orgName>
                                <address>
                                    <addrLine>Nakahara-Ku</addrLine>
                                    <postCode>1753, 211-8666</postCode>
                                    <settlement>Shimonumabe, Kawasaki</settlement>
                                    <region>Kanagawa</region>
                                    <country key="JP">Japan</country>
                                </address>
                            </affiliation>
                        </author>
                        <author>
                            <persName xmlns="http://www.tei-c.org/ns/1.0">
                                <forename type="first">Ryosuke</forename>
                                <surname>Isotani</surname>
                            </persName>
                            <affiliation key="aff0">
                                <orgName type="department">Media and Information Research Laboratories</orgName>
                                <orgName type="institution">NEC Corporation</orgName>
                                <address>
                                    <addrLine>Nakahara-Ku</addrLine>
                                    <postCode>1753, 211-8666</postCode>
                                    <settlement>Shimonumabe, Kawasaki</settlement>
                                    <region>Kanagawa</region>
                                    <country key="JP">Japan</country>
                                </address>
                            </affiliation>
                        </author>
                        <author>
                            <persName xmlns="http://www.tei-c.org/ns/1.0">
                                <forename type="first">Kenji</forename>
                                <surname>Satoh</surname>
                            </persName>
                            <email>k-satoh@da.jp.nec.coma-okumura@bx.jp.nec.com</email>
                            <affiliation key="aff0">
                                <orgName type="department">Media and Information Research Laboratories</orgName>
                                <orgName type="institution">NEC Corporation</orgName>
                                <address>
                                    <addrLine>Nakahara-Ku</addrLine>
                                    <postCode>1753, 211-8666</postCode>
                                    <settlement>Shimonumabe, Kawasaki</settlement>
                                    <region>Kanagawa</region>
                                    <country key="JP">Japan</country>
                                </address>
                            </affiliation>
                        </author>
                        <author>
                            <persName xmlns="http://www.tei-c.org/ns/1.0">
                                <forename type="first">Akitoshi</forename>
                                <surname>Okumura</surname>
                            </persName>
                            <affiliation key="aff0">
                                <orgName type="department">Media and Information Research Laboratories</orgName>
                                <orgName type="institution">NEC Corporation</orgName>
                                <address>
                                    <addrLine>Nakahara-Ku</addrLine>
                                    <postCode>1753, 211-8666</postCode>
                                    <settlement>Shimonumabe, Kawasaki</settlement>
                                    <region>Kanagawa</region>
                                    <country key="JP">Japan</country>
                                </address>
                            </affiliation>
                        </author>
                        <title level="a" type="main">Speech-Activated Text Retrieval System for Cellular Phones with Web
                            Browsing Capability
                        </title>
                    </analytic>
                    <monogr>
                        <imprint>
                            <date/>
                        </imprint>
                    </monogr>
                </biblStruct>
            </sourceDesc>
        </fileDesc>
        <profileDesc>
            <abstract>
                <div xmlns="http://www.tei-c.org/ns/1.0">
                    <head>Abstract</head>
                    <p>This paper describes a text retrieval system for cellular phones with Web browsing capability,
                        which accepts spoken queries over the cellular phone and provides the search result on the
                        cellular phone screen. This system recognizes spoken queries by large vocabulary continuous
                        speech recognition (LVCSR), retrieves relevant document by text retrieval, and provides the
                        search result on the World Wide Web by the integration of the Web and the voice systems. The
                        text retrieval in this system improves the performance for spoken short queries by: 1) utilizing
                        word pairs with dependency relations, 2) distinguishing affirmative and negative expressions,
                        and 3) converging synonyms. The LVCSR in this system shows enough performance level for speech
                        over the cellular phone with acoustic and language models derived from a query corpus with
                        target contents. The system constructed for user's manual for a cellular phone navigates users
                        to relevant passages for 81.4% of spoken queries.
                    </p>
                </div>
                <div xmlns="http://www.tei-c.org/ns/1.0">
                    <head n="1.">Introduction</head>
                    <p>Cellular phones are now widely used and those with Web browsing capability are becoming very
                        popular. Users can easily browse information provided on the World Wide Web such as news,
                        weather, and traffic report with the cellular phone screen in mobile environment. However,
                        obtaining necessary information from large database such as user's manual or travelers' guide is
                        quite a task for users since searching for appropriate information from seas of data requires
                        cumbersome key operations. I n m o s t cases, users have to carefully navigate through deep
                        hierarchical structures of menus or have to type in complex combination of keys to enter some
                        keywords.
                    </p>
                    <p>Text retrieval by voice input is one of the solutions for this problem. This paper presents a
                        telephone-based voice query retrieval system in Japanese which enables cellular phone users to
                        search through the user's manual. This system accepts spoken queries over the cellular phone
                        with large vocabulary continuous speech recognition (LVCSR) and retrieves relevant parts from
                        the user's manual with text retrieval. T h e r e s u l t s a r e p r o v i d e d t o t h e u s e
                        r a s a W e b p a g e b y s y n c h r o n o u s l y activating the Web and the voice
                        systems <ref type="bibr" target="#b6">(Yoshida et al., 2002)</ref>. Users can input queries
                        without complicated keystrokes and can view the list of results on the cellular phone screen.
                    </p>
                    <p>With respect to voice input systems, a large number of interactive voice responses (IVR) systems
                        and spoken dialogue systems has been designed and developed over the years (Zue, 1997). As for
                        user's manual retrieval systems which accept voice input, <ref type="bibr" target="#b3">Kawahara
                            et al. (2003)
                        </ref> has developed a spoken dialogue system for appliance manuals. However, they mainly focus
                        on the dialogue strategy to select the appropriate result on screen-less systems such as VTR and
                        FAX. On the other hand, retrieval methods for voice input have been examined on a TREC query set
                        <ref type="bibr" target="#b0">(Barnett et al., 1997;</ref>
                        <ref type="bibr" target="#b1">Crestani, 2000)</ref>.
                    </p>
                </div>
            </abstract>
        </profileDesc>
    </teiHeader>
    <text xml:lang="en">
        <body>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="1.">Introduction</head>
                <p>Cellular phones are now widely used and those with Web browsing capability are becoming very popular.
                    Users can easily browse information provided on the World Wide Web such as news, weather, and
                    traffic report with the cellular phone screen in mobile environment. However, obtaining necessary
                    information from large database such as user's manual or travelers' guide is quite a task for users
                    since searching for appropriate information from seas of data requires cumbersome key operations. I
                    n m o s t cases, users have to carefully navigate through deep hierarchical structures of menus or
                    have to type in complex combination of keys to enter some keywords.
                </p>
                <p>Text retrieval by voice input is one of the solutions for this problem. This paper presents a
                    telephone-based voice query retrieval system in Japanese which enables cellular phone users to
                    search through the user's manual. This system accepts spoken queries over the cellular phone with
                    large vocabulary continuous speech recognition (LVCSR) and retrieves relevant parts from the user's
                    manual with text retrieval. T h e r e s u l t s a r e p r o v i d e d t o t h e u s e r a s a W e b
                    p a g e b y s y n c h r o n o u s l y activating the Web and the voice systems <ref type="bibr"
                                                                                                        target="#b6">
                        (Yoshida et al., 2002)</ref>. Users can input queries without complicated keystrokes and can
                    view the list of results on the cellular phone screen.
                </p>
                <p>With respect to voice input systems, a large number of interactive voice responses (IVR) systems and
                    spoken dialogue systems has been designed and developed over the years <ref type="bibr"
                                                                                                target="#b7">(Zue,
                        1997)</ref>. As for user's manual retrieval systems which accept voice input, <ref type="bibr"
                                                                                                           target="#b3">
                        Kawahara et al. (2003)
                    </ref> has developed a spoken dialogue system for appliance manuals. However, they mainly focus on
                    the dialogue strategy to select the appropriate result on screen-less systems such as VTR and FAX.
                    On the other hand, retrieval methods for voice input have been examined on a TREC query set
                    <ref type="bibr" target="#b0">(Barnett et al., 1997;</ref>
                    <ref type="bibr" target="#b1">Crestani, 2000)</ref>. . However, text retrieval in TREC mainly aims
                    to search open domain documents from long queries, while our system is required to search closed
                    domain documents such as user's manuals based on short queries spoken over the cellular phone.
                </p>
                <p>In order to apply text retrieval technique to speech-activated user's manual retrieval, we have
                    investigated queries for searching manuals in addition to the text of the manuals from a linguistic
                    viewpoint. We found that text retrieval for a user's manual has the following three difficulties.
                </p>
                <list>
                    <item>1) The difficulty of identifying passages in a user's manual based on an individual word.
                    </item>
                    <item>2) The difficulty of distinguishing affirmative and negative sentences which mean two
                        different features in the manual.
                    </item>
                    <item>3) The difficulty of retrieving appropriate passages for a query using words not appearing in
                        the manual.
                    </item>
                </list>
                <p>This paper presents how we overcome these difficulties using three techniques: 1) utilizing word
                    pairs with dependency relations, 2) distinguishing affirmative and negative expressions by auxiliary
                    verbs, and 3) converging synonyms with synonym dictionary. The rest of the paper is organized as
                    follows. Section 2 describes the system configuration of our speech-activated text retrieval system
                    and how it works. Section 3 discusses the difficulties in text retrieval in our system and presents
                    our proposed techniques in detail. Section 4 shows the developed prototype system and Section 5
                    reports its evaluation results. Finally Section 6 concludes the paper.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="2.">Speech-Activated Text Retrieval System</head>
                <p>Our system receives spoken queries on the usage of the cellular phone and provides the list of
                    relevant passages in the user's manual. In this paper, a passage denotes a part of the document
                    corresponding to a feature in the user's manual. <ref type="figure" target="#fig_0">Figure 1</ref> shows
                    the configuration of our retrieval system. The telephone service module receives a phone call from
                    the user. This module prepares the search operation by calling the LVCSR module, which recognizes
                    the query spoken over the phone, and the text retrieval module, which provides the search result for
                    the query. The telephone service module sends the list of the relevant passages to the Web service
                    module, and then hangs up the phone. The Web service module provides the result to the user
                    according to the user's request via the internet. We assume that the cellular phone screen displays
                    about 30 letters per line and 15 lines of text according to the specifications of recent popular
                    cellular phones in Japan. We assign top ten potential passages as the search result and display the
                    title of them in order for the user to see with ease. <ref type="figure" target="#fig_1">Figure 2
                    </ref> shows the screen of the cellular phone displaying the search result.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="2.1.">System Configuration</head>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="2.2.">Example of Using the System</head>
                <p>This section describes how our system works. Our system works in Japanese, but in the following
                    section, English translation is provided for the reader's convenience. In our system, the user
                    obtains the relevant passage in the user's manual with the voice query according to the following
                    steps. <ref type="figure" target="#fig_2">Figure 3</ref>
                    <ref type="figure" target="#fig_3">Figure 4</ref>
                    <ref type="figure" target="#fig_4">Figure 5</ref>
                </p>
                <list>
                    <item>Step 1: The user first accesses the system's main page of our system with the cellular phone
                        (
                    </item>
                    <item>). The page contains two hyperlinks along with brief instructions and query examples.</item>
                    <item>Step 2: The user follows the first link labeled "Input query by voice." It is linked to the
                        telephone service module, allowing the user to call the telephone service module.
                    </item>
                    <item>Step 3: The user inputs a query following the voice guidance from the system. The LVCSR module
                        recognizes it and outputs the result text. The text retrieval module searches the user's manual
                        from recognized text and outputs the top ten results. The user goes back to the main page after
                        the telephone service module hangs up the phone.
                    </item>
                    <item>Step 4: The user follows the second link labeled "Show search results," which is linked to our
                        Web service module. Then the user views the result page which contains the title list of top ten
                        results (each passage consists of a title and a body).
                    </item>
                    <item>shows the example of the result page responding to the voice query "How to change my email
                        address."
                    </item>
                    <item>Step 5: By selecting a title of a passage from the result list, the user retrieves the
                        corresponding body of the passage (
                    </item>
                    <item>). If the result list contains no relevant passages, the user can go back to the homepage and
                        re-enter a query by speech.
                    </item>
                </list>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="3.">Text Retrieval for a User's Manual</head>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="3.1.">The Problems on User's Manual Retrieval</head>
                <p>In general, user's manual of equipment explains all functions extensively. Since the phrasing used in
                    a user's manual is often similar, expressions with small difference might appear in completely
                    different entries. We have investigated queries for searching manuals in addition to the text of the
                    manuals from a linguistic viewpoint and found that text retrieval for user's manual has the
                    following three difficulties.
                </p>
                <list>
                    <item>1) It is difficult to identify passages in a user's manual based on an individual word. For
                        example, a word "mail" shows up in passages explaining various functions such as sending mails,
                        receiving mails, composing mails, and many others. In order to overcome this difficulty, we need
                        to use relations between words.
                    </item>
                    <item>2) It is difficult to distinguish affirmative and negative sentences based on independent
                        words. Sentences with the same set of content words can mean two different features depending on
                        whether the sentence is in the affirmative or in the negative. This is often true in manual
                        writings where each function is described in pair: one activating and the other deactivating the
                        function (ex. "Sending the caller number" and "Not sending the caller number"). In order to
                        overcome this difficulty, we need to handle polarity indicated by auxiliary verbs.
                    </item>
                    <item>3) It is difficult to retrieve appropriate passages for a query using words not appearing in
                        the manual. While the expression denoting an object is generally standardized in a user's
                        manual, users often indicate the object with other expressions. In order to overcome this
                        difficulty, we need to assimilate difference of various synonymous expressions.
                    </item>
                </list>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="3.2.">The Approaches for User's Manual Retrieval</head>
                <p>The system retrieves relevant passages from the user's manual with a word-based text retrieval
                    method. The system generates indexes for content words in passages and obtains relevant passages
                    from the words in the query based on Okapi BM25 probabilistic retrieval model without relevance
                    feedback in principle <ref type="bibr">(Robertson et al., 1993)</ref>. In this model, the weight W
                    of a passage P for a query Q is defined as follows:
                </p>
                <formula xml:id="formula_0">   Q T T TW W ) ( qtf k qtf k tf K k tf k w T TW           2 2
                    1 1 ) 1 ( ) 1 ( ) ( 5 . 0 5 . 0 log     n n N w AVPL PL b b K     ) 1 (
                </formula>
                <p>Here T denotes a term in the query Q, N denotes the number of passages in the whole text, n denotes
                    the number of passages containing the term T, tf denotes the frequency of occurrence of the term T
                    within the passage P, qtf denotes the frequency of occurrence of the term T within the query Q, PL
                    denotes the length of the passage P, and AVPL denotes the average length of all passages. k 1 , k 2
                    , and b are predefined constants.
                </p>
                <p>In order to overcome the difficulties stated previously, we have expanded the retrieval model with
                    the following three techniques.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head>1) Utilization of word pairs with dependency relations</head>
                <p>This technique assigns larger weight for passages including the same word pairs with dependency
                    relations as in the query. The system uses the following weight W wp , which is simple extension of
                    W:
                </p>
                <formula xml:id="formula_1">W k W NP   wp wp</formula>
                <p>where NP denotes the number of word pairs which appear both in the passage P and the query Q with
                    dependency relations. k wp is predefined constants. We detect the dependency between words by
                    shallow dependency analysis without parsing. The system assigns depend-to and depend-from attributes
                    to each word based on its part of speech and connects them according to the surrounding relationship <ref
                            type="bibr" target="#b5">(Satoh et al., 2003)</ref>.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head>2) Distinction between the negative and the affirmative phrases by auxiliary verbs</head>
                <p>This technique assigns the different weight on the term according to the condition whether an
                    auxiliary verb indicating negative polarity follows after the term. The system adds this condition
                    to each word after morphological analysis, and distinguishes words with different conditions. The
                    system uses the following weight W aux instead of W:
                </p>
                <formula xml:id="formula_2">                    Q T Q T T TW k T TW T TW k T TW W )
                    ( ) ( ) ( ) ( aux aux aux
                </formula>
                <p>where T + denotes the term T with this condition and T -denotes the term T without this condition. k
                    aux is predefined constants.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head>3) Converging synonyms</head>
                <p>This technique assumes the occurrence of synonymous expressions for a word as the occurrence of the
                    word itself in calculating the weight. The system converges various synonymous expressions into the
                    standard expression by using predefined synonym dictionary. The system accepts a set of words with
                    dependency relations as a synonymous expression in order to converge complex synonymous expressions. <ref
                            type="table" target="#tab_0">Table 1
                    </ref> shows an example of a synonym dictionary. An arrow sign denotes a dependency relation between
                    words.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="4.">Prototype System</head>
                <p>We have constructed a prototype system to search through the manuals for cellular phone users <ref
                        type="bibr" target="#b2">(Ishikawa et al., 2004)</ref>. The user's manual contains about 14,000
                    passages and consists of about 4,000 unique words. The prototype system works in real time according
                    to the user's operation.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="4.1.">LVCSR Module</head>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="4.1.1.">Language Model</head>
                <p>A statistical language model (LM) with word and class n-gram estimates is used in our system. Word
                    3-gram is backed off to word 2-gram, and word 2-gram is backed off to class 2-gram. Partof-speech
                    patterns are used as the classes of each word. The LM is trained on a text corpus of query samples
                    for our target user's manual. Nouns in the manual document are added to the recognition dictionary
                    apart from the training. A total of 15,000 queries were manually constructed and used for training
                    the LM. The final LM for the prototype system has about 4,000 words in the recognition vocabulary,
                    about 20,000 word 2-gram entries, and about 40,000 word 3-gram entries.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="4.1.2.">Acoustic Model</head>
                <p>A speech signal is sampled at 8kHz, with MFCC analysis frame rate of 10ms. Spectral subtraction (SS)
                    is applied to remove stationary additive noises. The feature set includes MFCC, pitch, and energy
                    with their time derivatives. The LVCSR decoder supports triphone HMMs with tree-based state
                    clustering on phonetic contexts. The state emission probability is represented by Gaussian mixtures
                    with diagonal covariance matrices. For the prototype system, Gender-dependent acoustic models were
                    prepared by the training on the speech corpus with 200,000 sentences read by 1,385 speakers
                    collected through telephone line.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="4.1.3.">LVCSR Decoder</head>
                <p>The LVCSR decoder recognizes the query utterances with the triphone acoustic model, the statistical
                    language model, and a tree-structured word dictionary. It performs two-stage processing. On the
                    first stage, input speech is decoded by frame-synchronous beam search to generate a word candidate
                    graph using the acoustic model, 2-gram language model, and the word dictionary. On the second stage,
                    the graph is searched to find the optimal word sequence using the 3-gram language model. Both male
                    and female acoustic models are used and decoding is performed independently for each model except
                    for the common beam pruning in every frame. Recognition results by male and female acoustic models
                    are compared and the one with better score is used as the result. Gender-dependent models improve
                    the recognition accuracy while curbing the increase of the computational amount by common beam
                    pruning.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="4.2.">Text Retrieval Module</head>
                <p>All the techniques described in Section 3.2 are implemented on the text retrieval module in the
                    system. We fixed the constants as follows according to the preliminary experiments using query
                    samples developed for training the LM:
                </p>
                <formula xml:id="formula_3">3 . 0 , 3 . 1 , 3 . 0 , 1000 , 100 aux wp 2 1      k k b k k</formula>
                <p>We developed the synonym dictionary with about 500 entries to converge synonymous expressions used to
                    describe cellular phone functions.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="5.">Evaluation</head>
                <p>In order to evaluate the usefulness of our system, we have composed 150 new queries independently of
                    the query corpus used for configuring the system. We have used 110 queries for evaluation,
                    eliminating 40 queries without relevant passages in the manual. <ref type="table" target="#tab_1">
                        Table 2
                    </ref> shows some examples of the queries used for the evaluation. Each query contains 3.8 words in
                    average. The retrieval success rate, which we adopted as a criterion, measures how well the system
                    is able to provide a relevant passage within the top predefined number of result passages. We have
                    calculated the retrieval success rates at 1, 5, and 10 passages for several conditions. In order to
                    discuss the effect of each technique presented in Section 3.2, we first present the result for
                    transcriptions of the queries among the following text retrieval methods.
                </p>
                <p>Method BL: This is the baseline method with no techniques applied. Method WP: This method utilizes
                    word pairs with dependency relations. Method WP+AUX: This method distinguishes between the negative
                    and the affirmative phrases by auxiliary verbs in addition to the method WP. Method ALL: This method
                    converges synonyms in addition to the method WP+AUX. This is the same condition as the prototype
                    system. <ref type="table" target="#tab_2">Table 3</ref> summarizes the result. The result shows each
                    of the three techniques has contributed to the improvement of the retrieval success rate.
                    Especially, converging synonyms enhances the performance as derived from the difference between
                    methods WP+AUX and ALL. Next we present the performance of the total system. <ref type="table"
                                                                                                      target="#tab_3">
                        Table 4
                    </ref> shows the result for 660 utterances of the queries by 18 speakers where the LVCSR module and
                    the text retrieval module in the prototype system are used. The retrieval success rates for
                    utterances are almost the same as those for transcription. Since the cellular phones used in this
                    system can display about 10 lines on the average, the 10th retrieval rate represents the rate of
                    successfully delivering the passage requested by the user. The result shows that the system designed
                    for cellular phone user's manual was able to direct user to appropriate information at 81.4%, which
                    is sufficient for practical use.
                </p>
            </div>
            <div xmlns="http://www.tei-c.org/ns/1.0">
                <head n="6.">Conclusions</head>
                <p>In this paper, we presented a voice query retrieval system in Japanese applied to document search on
                    user's manual for cellular phones with Web access capability. The system recognizes user's naturally
                    spoken queries over the cellular phone by LVCSR and retrieves the relevant passages by text
                    retrieval and then provides the output on the cellular phone screen. In order to improve the
                    performance for spoken short queries, we apply three techniques into text retrieval: 1) utilizing
                    word pairs with dependency relations, 2) distinguishing affirmative and negative expressions, and 3)
                    converging synonyms. With respect to LVCSR for speech over the cellular phone, we adopt acoustic and
                    language models derived from a query corpus for the target user's manual. The evaluation on the
                    system designed for cellular phone user's manual shows that the system is able to direct users to
                    appropriate data at 81.4% of the time, if the matching passage exists in the manual. Our next step
                    is to apply this system to different contents such as travelers' guide and customer surveys. We plan
                    to clarify the problems for different contents and to enhance the portability of this system.
                </p>
            </div>
            <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0">
                <head>Figure 1 :</head>
                <label>1</label>
                <figDesc>Figure 1: The configuration of the prototype system.</figDesc>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1">
                <head>Figure 2 :</head>
                <label>2</label>
                <figDesc>Figure 2: The screen of the cellular phone displaying the search result.</figDesc>
                <graphic url="Y05-1024_assets/home/doc/Grobid/Development/grobid/grobid-home/tmp"
                         coords="2,393.36,70.93,120.00,155.76" type="bitmap"/>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2">
                <head>Figure 3 :</head>
                <label>3</label>
                <figDesc>Figure 3: The main page of our system.</figDesc>
                <graphic url="Y05-1024_assets/home/doc/Grobid/Development/grobid/grobid-home/tmp"
                         coords="3,61.44,70.93,146.40,184.32" type="bitmap"/>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3">
                <head>Figure 4 :</head>
                <label>4</label>
                <figDesc>Figure 4: The result page displaying the title list of top ten results for the query.</figDesc>
                <graphic url="Y05-1024_assets/home/doc/Grobid/Development/grobid/grobid-home/tmp"
                         coords="3,225.60,70.93,144.00,184.32" type="bitmap"/>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4">
                <head>Figure 5 :</head>
                <label>5</label>
                <figDesc>Figure 5: The body of the passage displayed when the user selects the title in Figure 4.
                </figDesc>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5">
                <head>Figure 4</head>
                <label>4</label>
                <figDesc>Figure 5: The body of the passage displayed when the user selects the title in Figure 4.
                </figDesc>
                <graphic url="Y05-1024_assets/home/doc/Grobid/Development/grobid/grobid-home/tmp"
                         coords="3,388.56,70.93,144.00,184.32" type="bitmap"/>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6">
                <head></head>
                <label></label>
                <figDesc>Figure 5: The body of the passage displayed when the user selects the title in Figure 4.
                </figDesc>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true">
                <head>Table 1 :</head>
                <label>1</label>
                <figDesc>An example of a synonym dictionary</figDesc>
                <table>Standard Expression
                    Synonymous Expressions
                    saito
                    webu
                    hômupêji
                    (site)
                    (web)
                    (homepage)
                    chakushin'on
                    chakushinmerodî
                    yobidashion
                    (ringtone)
                    (ring melody)
                    (phone beep)
                    ridaiaru
                    môichido  kakeru
                    (redial)
                    (again  call)

                </table>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false">
                <head>Table 2 :</head>
                <label>2</label>
                <figDesc>Examples of queries used for evaluation. Shashin-o mêru-de okuritai (I want to send a picture
                    via email) Aikon-o desukutoppu-ni tôroku shitai (I want to register a new icon on the desktop)
                    Jushin-shita mêru-o minagara henshin mêru-o sakusei-suru hôhô (How to write a reply mail while
                    looking at the incoming mail)
                </figDesc>
                <table></table>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true">
                <head>Table 3 :</head>
                <label>3</label>
                <figDesc>The retrieval success rate for the transcriptions of queries.</figDesc>
                <table>Retrieval Success Rate for Transcriptions
                    Number of
                    Result
                    Passages
                    BL
                    WP
                    WP+AUX
                    ALL

                    1
                    40.0%
                    42.7%
                    44.5%
                    49.1%
                    5
                    65.5%
                    69.1%
                    70.0%
                    77.3%
                    10
                    73.6%
                    73.6%
                    74.5%
                    87.3%

                </table>
            </figure>
            <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true">
                <head>Table 4 :</head>
                <label>4</label>
                <figDesc>The retrieval success rate for the utterances of queries.</figDesc>
                <table>Number of
                    Result Passages

                    Retrieval Success Rate
                    for Utterances
                    1
                    44.3%
                    5
                    72.5%
                    10
                    81.4%

                </table>
            </figure>
        </body>
        <back>
            <div type="references">

                <listBibl>

                    <biblStruct xml:id="b0">
                        <analytic>
                            <title level="a" type="main">Experiments in Spoken Queries for Document Retrieval</title>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">J</forename>
                                    <surname>Barnett</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">S</forename>
                                    <surname>Anderson</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">J</forename>
                                    <surname>Broglio</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">M</forename>
                                    <surname>Singh</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">R</forename>
                                    <surname>Hudson</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">S</forename>
                                    <forename type="middle">W</forename>
                                    <surname>Kuo</surname>
                                </persName>
                            </author>
                        </analytic>
                        <monogr>
                            <title level="m">Proceedings of Eurospeech&apos;97</title>
                            <meeting>Eurospeech&apos;97</meeting>
                            <imprint>
                                <date type="published" when="1997"/>
                                <biblScope unit="page" from="1323" to="1326"/>
                            </imprint>
                        </monogr>
                    </biblStruct>

                    <biblStruct xml:id="b1">
                        <analytic>
                            <title level="a" type="main">Word recognition errors and relevance feedback in spoken query
                                processing
                            </title>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">F</forename>
                                    <surname>Crestani</surname>
                                </persName>
                            </author>
                        </analytic>
                        <monogr>
                            <title level="m">Proceedings of the Fourth International Conference on Flexible Query
                                Answering Systems
                            </title>
                            <meeting>the Fourth International Conference on Flexible Query Answering Systems</meeting>
                            <imprint>
                                <date type="published" when="2000"/>
                                <biblScope unit="page" from="267" to="281"/>
                            </imprint>
                        </monogr>
                    </biblStruct>

                    <biblStruct xml:id="b2">
                        <analytic>
                            <title level="a" type="main">Speechactivated Text Retrieval System for Multimodal Cellular
                                Phones
                            </title>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">S</forename>
                                    <surname>Ishikawa</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">T</forename>
                                    <surname>Ikeda</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">K</forename>
                                    <surname>Miki</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">F</forename>
                                    <surname>Adachi</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">R</forename>
                                    <surname>Isotani</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">K</forename>
                                    <surname>Iso</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">A</forename>
                                    <surname>Okumura</surname>
                                </persName>
                            </author>
                        </analytic>
                        <monogr>
                            <title level="j">Proceedings of ICASSP</title>
                            <imprint>
                                <date type="published" when="2004"/>
                            </imprint>
                        </monogr>
                    </biblStruct>

                    <biblStruct xml:id="b3">
                        <analytic>
                            <title level="a" type="main">Spoken Dialogue System for Queries on Appliance Manuals using
                                Hierarchical Confirmation Strategy
                            </title>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">T</forename>
                                    <surname>Kawahara</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">R</forename>
                                    <surname>Ito</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">K</forename>
                                    <surname>Komatani</surname>
                                </persName>
                            </author>
                        </analytic>
                        <monogr>
                            <title level="m">Proceedings of Eurospeech</title>
                            <meeting>Eurospeech</meeting>
                            <imprint>
                                <date type="published" when="2003"/>
                                <biblScope unit="page" from="1701" to="1704"/>
                            </imprint>
                        </monogr>
                    </biblStruct>

                    <biblStruct xml:id="b4">
                        <analytic>
                            <title level="a" type="main">Okapi at TREC-3</title>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">S</forename>
                                    <forename type="middle">E</forename>
                                    <surname>Robertson</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">S</forename>
                                    <surname>Walker</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">S</forename>
                                    <surname>Jones</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">M</forename>
                                    <surname>Hancock-Beaulieu</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">M</forename>
                                    <surname>Gatford</surname>
                                </persName>
                            </author>
                        </analytic>
                        <monogr>
                            <title level="m">Proceedings of the 3rd Text Retrieval Conference (TREC-3)</title>
                            <meeting>the 3rd Text Retrieval Conference (TREC-3)</meeting>
                            <imprint>
                                <date type="published" when="1995"/>
                                <biblScope unit="page" from="109" to="126"/>
                            </imprint>
                        </monogr>
                    </biblStruct>

                    <biblStruct xml:id="b5">
                        <analytic>
                            <title level="a" type="main">Design and Development of Japanese Processing Middleware for
                                Customer Relationship Management
                            </title>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">K</forename>
                                    <surname>Satoh</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">T</forename>
                                    <surname>Ikeda</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">T</forename>
                                    <surname>Nakata</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">S</forename>
                                    <surname>Osada</surname>
                                </persName>
                            </author>
                        </analytic>
                        <monogr>
                            <title level="m">Proceedings of the 9th Annual Meeting of The Association for Natural
                                Language Processing
                            </title>
                            <meeting>the 9th Annual Meeting of The Association for Natural Language Processing</meeting>
                            <imprint>
                                <date type="published" when="2003"/>
                                <biblScope unit="page" from="109" to="112"/>
                            </imprint>
                        </monogr>
                        <note>in Japanese</note>
                    </biblStruct>

                    <biblStruct xml:id="b6">
                        <analytic>
                            <title level="a" type="main">Human-Voice Interface</title>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">K</forename>
                                    <surname>Yoshida</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">H</forename>
                                    <surname>Hagane</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">K</forename>
                                    <surname>Hatazaki</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">K</forename>
                                    <surname>Iso</surname>
                                </persName>
                            </author>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">H</forename>
                                    <surname>Hattori</surname>
                                </persName>
                            </author>
                        </analytic>
                        <monogr>
                            <title level="j">NEC Research &amp; Development</title>
                            <imprint>
                                <biblScope unit="volume">43</biblScope>
                                <biblScope unit="issue">1</biblScope>
                                <biblScope unit="page" from="33" to="36"/>
                                <date type="published" when="2002"/>
                            </imprint>
                        </monogr>
                    </biblStruct>

                    <biblStruct xml:id="b7">
                        <monogr>
                            <author>
                                <persName xmlns="http://www.tei-c.org/ns/1.0">
                                    <forename type="first">V</forename>
                                    <surname>Zue</surname>
                                </persName>
                            </author>
                            <title level="m">Conversational Interfaces: Advances and Challenges. Proceedings of
                                Eurospeech &apos;97
                            </title>
                            <imprint>
                                <date type="published" when="1997"/>
                                <biblScope unit="page" from="9" to="18"/>
                            </imprint>
                        </monogr>
                    </biblStruct>

                </listBibl>
            </div>
        </back>
    </text>
</TEI>
